{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task name : simple migration\n",
    "\n",
    "about the task :I had to fetch the live logs of some script related to fetaching data from one database to another database like in big data.I used to here django,celery to schedule the logs per second and javascript. \n",
    "\n",
    "Work Experience\n",
    "Software Engineer\n",
    "Echelon Edge\n",
    "Date Range (e.g., MM/YYYY - MM/YYYY)\n",
    "\n",
    "Designed and implemented a live log monitoring system for database migration processes between source and target databases.\n",
    "Utilized SSH protocols to securely connect and execute external scripts on remote servers, fetching logs in real time.\n",
    "Developed and scheduled automated tasks using Django and Celery, ensuring logs were retrieved and updated at per-second intervals.\n",
    "Integrated JavaScript for dynamic log visualization, enhancing monitoring efficiency and user experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task name : external query \n",
    "about the task : \n",
    "    > The task was if any database query is written in the text-editor then that will work and get data related to that query. \n",
    "    > My job was that for the query if sumbitted that query then it fetch the records from the database and I have to rendor that records on ui wiht <server-side pagination>. \n",
    "    > I used libraris like django for backend and for frontend javascrpit and jquery. \n",
    "    \n",
    "Software Engineer\n",
    "Echelon Edge\n",
    "Date Range (e.g., MM/YYYY - MM/YYYY)\n",
    "\n",
    "Developed a dynamic query execution system, enabling users to write and execute database queries directly from a text editor.\n",
    "Implemented backend functionality using Django to fetch query results from MySQL, PostgreSQL, and Oracle databases, ensuring compatibility across multiple database systems.\n",
    "Rendered fetched records on the UI with server-side pagination, improving performance and scalability for large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task name : mysql database backup system \n",
    "about the task : \n",
    "    > to take backup increementally for the mysql database. \n",
    "    > I done the R & D on how to take incremental backup in mysql database. \n",
    "    > I find the some commands of mysql database by which I performed mysql incremental database backup\n",
    "\n",
    "Work Experience\n",
    "Software Engineer\n",
    "Echelon Edge\n",
    "Date Range (e.g., MM/YYYY - MM/YYYY)\n",
    "\n",
    "Researched and implemented an incremental backup system for MySQL databases, ensuring data security and efficient storage management.\n",
    "Conducted in-depth R&D to identify optimal commands and methodologies for performing incremental backups in MySQL.\n",
    "Successfully automated incremental backup processes using MySQL commands, enhancing reliability and minimizing downtime during backup operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task name : Generic pipeline \n",
    "about the task : \n",
    "    > On uploading the dataset automatically apply preprocessing like cleaning and feature engeenring etc and then cleaned data automatically passed to multiple model(algrithms)with the help of pipeline(automated training and prediction) for classification problem if otherwise regression problems according to the dataset that's it about the task. \n",
    "    > I used here numpy,pandas and scikit-learn and scikit-learn pipeline.\n",
    "\n",
    "Task Name : Generic Machine Learning Pipeline for Automated Data Processing\n",
    "Description:\n",
    "Developed a generic machine learning pipeline that automates the entire workflow from data preprocessing to model training and prediction. The system dynamically adapts to the dataset type (classification or regression) and ensures seamless execution of machine learning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
